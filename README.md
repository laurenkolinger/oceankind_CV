# oceankind_CV
Computer vision pipeline for processing data from CVAT to train/validate/test with ultralytics for classification, detection and segmentation. Designed for Oceankind collaborators QUT, UVI, Berkeley and Point Blue. 

# Get started

Clone this repository 

## Install miniconda
*If you have an existing conda installation, skip this step*

Follow instructions for your platform https://docs.anaconda.com/miniconda/

## Create conda environment and install ultralytics
As per https://docs.ultralytics.com/quickstart/#install-ultralytics 

```bash
conda create --name OK_CV 
conda activate OK_CV
conda install -c pytorch -c nvidia -c conda-forge pytorch torchvision pytorch-cuda=11.8
```

Instead of conda installing ultralytics, install from git for development

In an appropriate folder: 
```bash
# Clone the ultralytics repository
git clone https://github.com/ultralytics/ultralytics

# Navigate to the cloned directory
cd ultralytics

# Install the package in editable mode for development
pip install -e .
```

## Check installation
Make sure the install was successful. If CUDA is not available AND you have a CUDA enabled GPU, make sure it is set up correctly. 

Installing pytorch separately may help https://pytorch.org/get-started/locally/ 

```bash
python tools/test_install.py
```

# Bounding boxes
For converting CVAT Segment Anything mask annotations to YOLO format for training.

Go to Project -> Open Task -> Export annotations in COCO 1.0 format

*CVAT has YOLOv8 bounding boxes built in as a format, however it does not convert from segmentation labels to bounding boxes. Use this if the annotations are already in bounding box format*

Download the zip and extract. It should be in the format annotation/instances_default.json

If you have many different CVAT tasks for the same model, extract all into the same folder in following format:
```
└── Raw_labels
    ├── 0-100
        └── annotations
            └── instances_default.json
    ├── 101-200
        └── annotations
            └── instances_default.json
    └── 201-300
        └── annotations
            └── instances_default.json          
```

To convert to YOLO format:

```bash
# Run conversion script
python tools/coco_to_yolo_format.py --json /Data/CVAT_example/Raw_labels/*/*/*.json --save /Data/Processed/CVAT_example/ --merge /Data/CVAT_example/class_merger.yaml --newclasses living,not_living

## For a single json:
--json /Data/Raw_labels/0-100/annotations/instances_default.json 

Do you need to merge classes? Y/N: Y
## if No, the script will complete --merge and --newclasses are ignored, if Yes:

Do you have an existing merge file? Y/N:
## if No:
--newclasses is required, --merge is ignored
## The class merger yaml will be generated and script will exit.
## You will need to edit this file and save. Read class_merger section for more information.
## Run conversion script again, this time entering Y for existing merge file. 

## if Yes:
--merge is required, --newclasses is ignored
```
The output will be a txt file for each image in YOLO format in the folder /Data/Processed/CVAT_example/all_labels


## class_merger
The class_merger.yaml is automatically generated by the tools/coco_to_yolo_format.py. See an example in examples/class_merger.yaml

To associate an "old_class" to a "new_class", add the number associated to the new class at the end of the line. For example, the examples/class_merger.yaml should be edited to:

```yaml
new_classes:
  0: alive
  1: not_alive
old_classes:
  0: dog,0
  1: cat,0
  2: person,0
  3: laptop,1
```

Save and rerun tools/coco_to_yolo_format.py, this time providing the path to the edited class_merger.yaml

# Data preparation



